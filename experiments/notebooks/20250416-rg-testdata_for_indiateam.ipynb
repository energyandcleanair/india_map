{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f2c0137",
   "metadata": {},
   "source": [
    "Creating yearly and monthly tiffs for the India team to evaluate the feasibility of the modelled data to their envisioned use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a013a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import netCDF4\n",
    "import geopandas as gpd\n",
    "import datetime\n",
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbc9acb",
   "metadata": {},
   "source": [
    "### Get data\n",
    "PM2.5 data generated by the full model are downloaded from zenodo (https://zenodo.org/records/13694585); all files matching full_model_YYYY.zip where downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6844ce48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already unzipped ../../../../on_zenodo/full_model_2020.zip\n",
      "Already unzipped ../../../../on_zenodo/full_model_2023.zip\n",
      "Already unzipped ../../../../on_zenodo/full_model_2018.zip\n",
      "Already unzipped ../../../../on_zenodo/full_model_2021.zip\n",
      "Already unzipped ../../../../on_zenodo/full_model_2022.zip\n",
      "Already unzipped ../../../../on_zenodo/full_model_2019.zip\n"
     ]
    }
   ],
   "source": [
    "data_path = '../../../../on_zenodo/'\n",
    "\n",
    "# find all zip files\n",
    "files = glob.glob(data_path + 'full_model_*.zip')\n",
    "\n",
    "# for each file, check if unzipped folder exists, and it not, unzip\n",
    "for file in files:\n",
    "    if os.path.exists(file[:-4]):\n",
    "        print(f\"Already unzipped {file}\")\n",
    "    else:\n",
    "        print(f\"Unzipping {file}\")\n",
    "        os.system(f\"unzip {file} -d {file[:-4]}\")\n",
    "\n",
    "# find all nc4 files that match V01FL_PM25_India_YYYYMMDD.nc4\n",
    "file_list = glob.glob(data_path + 'full_model_*/*/V01FL_PM25_India_*.nc4')\n",
    "\n",
    "# first file in 2018 is from 10.7., last file in 2023 30.9.\n",
    "# calculate number of days\n",
    "days =  (datetime.datetime(2023, 9, 30) - datetime.datetime(2018, 7, 10)).days + 1\n",
    "# check that number of files matches number of days\n",
    "\n",
    "assert len(file_list) == days, f\"Number of files {len(file_list)} does not match number of days {days}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110359f5",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca799e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function which adds a time dimension to a DataArray, and fill it with a arbitrary date:\n",
    "# added using the filename to get the datestring\n",
    "def add_time_dim(xds):\n",
    "    filename = xds.encoding['source']\n",
    "    date_str = os.path.basename(filename).split('_')[-1][:8]\n",
    "    xds = xds.expand_dims(time = [datetime.datetime.strptime(date_str, '%Y%m%d')])\n",
    "    return xds\n",
    "\n",
    "# ds = xr.open_dataset(file_list[0], engine='netcdf4', decode_coords=\"all\")\n",
    "file_list.sort()\n",
    "# open all files, and add time dimension\n",
    "ds = xr.open_mfdataset(file_list, combine='nested', concat_dim='time', decode_coords=\"all\", engine='netcdf4', preprocess = add_time_dim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4432c71d",
   "metadata": {},
   "source": [
    "### Calculate temporal means and save to geotiffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2aa68f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_data_path = '../../../../sample_data'\n",
    "os.makedirs(out_data_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0677bbd",
   "metadata": {},
   "source": [
    "#### Annual means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d99084b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate yearly mean\n",
    "ds_yearly = ds.resample(time='YS').mean()\n",
    "\n",
    "# # plot one year for sanity check\n",
    "# ds_yearly.isel(time=0)['pm25_pred'].plot()\n",
    "\n",
    "# save to geotiff\n",
    "\n",
    "for time in ds_yearly.time.values:\n",
    "\n",
    "    # select pm25 variable and year for file\n",
    "    data_out = ds_yearly.sel(time=time)['pm25_pred']\n",
    "\n",
    "    # full filename\n",
    "    filename_out = os.path.join(out_data_path, 'yearly', f'PM25_{ pd.to_datetime(time).strftime('%Y')}.tif')\n",
    "\n",
    "    # save the file\n",
    "    os.makedirs(os.path.dirname(filename_out), exist_ok=True)\n",
    "    data_out.rio.to_raster(filename_out, driver='GTiff')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793e8a23",
   "metadata": {},
   "source": [
    "#### Yearly means for financial means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b4891f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work/.cache/pypoetry/virtualenvs/india-map-JHchGCJw-py3.12/lib/python3.12/site-packages/xarray/groupers.py:490: FutureWarning: 'AS-APR' is deprecated and will be removed in a future version, please use 'YS-APR' instead.\n",
      "  self.index_grouper = pd.Grouper(\n"
     ]
    }
   ],
   "source": [
    "# calculate yearly mean, starting from 1st April of each year\n",
    "ds_yearly = ds.resample(time='AS-APR').mean()\n",
    "\n",
    "# # plot one year for sanity check\n",
    "# ds_yearly.isel(time=0)['pm25_pred'].plot()\n",
    "\n",
    "# save to geotiff\n",
    "\n",
    "for time in ds_yearly.time.values:\n",
    "\n",
    "    # select pm25 variable and year for file\n",
    "    data_out = ds_yearly.sel(time=time)['pm25_pred']\n",
    "\n",
    "    # full filename\n",
    "    filename_out = os.path.join(out_data_path, 'financial_yearly', f'PM25_{ pd.to_datetime(time).strftime('%Y')}.tif')\n",
    "\n",
    "    # save the file\n",
    "    os.makedirs(os.path.dirname(filename_out), exist_ok=True)\n",
    "    data_out.rio.to_raster(filename_out, driver='GTiff')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb62e453",
   "metadata": {},
   "source": [
    "#### Monthly means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e71e67d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate yearly mean\n",
    "ds_monly = ds.resample(time='MS').mean()\n",
    "\n",
    "# # plot one year for sanity check\n",
    "# ds_monly.isel(time=0)['pm25_pred'].plot()\n",
    "\n",
    "# save to geotiff\n",
    "\n",
    "for time in ds_monly.time.values:\n",
    "\n",
    "    # select pm25 variable and year for file\n",
    "    data_out = ds_monly.sel(time=time)['pm25_pred']\n",
    "\n",
    "    # full filename\n",
    "    filename_out = os.path.join(out_data_path, 'monthly', f'PM25_{ pd.to_datetime(time).strftime('%Y%m')}.tif')\n",
    "\n",
    "    # save the file\n",
    "    os.makedirs(os.path.dirname(filename_out), exist_ok=True)\n",
    "    data_out.rio.to_raster(filename_out, driver='GTiff')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "india-map-JHchGCJw-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
